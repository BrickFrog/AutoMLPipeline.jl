<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Pipeline · AutoMLPipeline Documentation</title><link href="https://fonts.googleapis.com/css?family=Lato|Roboto+Mono" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.11.2/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.11.2/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.11.2/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.11.1/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="../.."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../../assets/documenter.js"></script><script src="../../siteinfo.js"></script><script src="../../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-dark.css" data-theme-name="documenter-dark"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../../assets/themeswap.js"></script></head><body><div id="documenter"><nav class="docs-sidebar"><div class="docs-package-name"><span class="docs-autofit">AutoMLPipeline Documentation</span></div><form class="docs-search" action="../../search/"><input class="docs-search-query" id="documenter-search-query" name="q" type="text" placeholder="Search docs"/></form><ul class="docs-menu"><li><a class="tocitem" href="../../">HOME</a></li><li><span class="tocitem">Tutorial</span><ul><li class="is-active"><a class="tocitem" href>Pipeline</a></li><li><a class="tocitem" href="../preprocessing/">Preprocessing</a></li><li><a class="tocitem" href="../learning/">Training and Validation</a></li><li><a class="tocitem" href="../extending/">Extending AutoMLPipeline</a></li></ul></li><li><span class="tocitem">Manual</span><ul><li><a class="tocitem" href="../../man/pipeline/">Pipeline</a></li><li><a class="tocitem" href="../../man/preprocessors/">Preprocessors</a></li><li><a class="tocitem" href="../../man/learners/">Learners</a></li><li><a class="tocitem" href="../../man/metaensembles/">Meta-Ensembles</a></li></ul></li><li><span class="tocitem">Library</span><ul><li><a class="tocitem" href="../../lib/typesfunctions/">Types and Functions</a></li></ul></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><nav class="breadcrumb"><ul class="is-hidden-mobile"><li><a class="is-disabled">Tutorial</a></li><li class="is-active"><a href>Pipeline</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Pipeline</a></li></ul></nav><div class="docs-right"><a class="docs-edit-link" href="https://github.com/IBM/AutoMLPipeline.jl/blob/master/docs/src/tutorial/pipeline.md" title="Edit on GitHub"><span class="docs-icon fab"></span><span class="docs-label is-hidden-touch">Edit on GitHub</span></a><a class="docs-settings-button fas fa-cog" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-sidebar-button fa fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a></div></header><article class="content" id="documenter-page"><h1 id="PipelineUsage"><a class="docs-heading-anchor" href="#PipelineUsage">Pipeline</a><a id="PipelineUsage-1"></a><a class="docs-heading-anchor-permalink" href="#PipelineUsage" title="Permalink"></a></h1><p><em>A tutorial for using the <code>@pipeline</code> expression</em></p><h3 id="Dataset"><a class="docs-heading-anchor" href="#Dataset">Dataset</a><a id="Dataset-1"></a><a class="docs-heading-anchor-permalink" href="#Dataset" title="Permalink"></a></h3><p>Let us start the tutorial by loading the dataset.</p><pre><code class="language-">using AutoMLPipeline
using CSV
profbdata = CSV.File(joinpath(dirname(pathof(AutoMLPipeline)),&quot;../data/profb.csv&quot;)) |&gt; DataFrame
X = profbdata[:,2:end] 
Y = profbdata[:,1] |&gt; Vector
nothing #hide</code></pre><p>We can check the data by showing the first 5 rows:</p><pre><code class="language-julia-repl">julia&gt; show5(df)=first(df,5); # show first 5 rows

julia&gt; show5(profbdata)
ERROR: UndefVarError: profbdata not defined</code></pre><p>This dataset is a collection of pro football scores with the following variables and their descriptions:</p><ul><li>Home/Away = Favored team is at home or away</li><li>Favorite Points = Points scored by the favored team</li><li>Underdog Points = Points scored by the underdog team</li><li>Pointspread = Oddsmaker&#39;s points to handicap the favored team</li><li>Favorite Name = Code for favored team&#39;s name</li><li>Underdog name = Code for underdog&#39;s name</li><li>Year = 89, 90, or 91</li></ul><div class="admonition is-info"><header class="admonition-header">Note</header><div class="admonition-body"><p>For the purpose of this tutorial, we will use the first column, Home vs Away, as the target variable to be predicted using the other columns as input features. For this target output, we are trying to ask whether the model can learn the patterns from its input features to predict whether the game was played at home or away. Since the input features have both categorical and numerical features, the dataset is a good basis to describe  how to extract these two types of features, preprocessed them, and learn the mapping using a one-liner pipeline expression.</p></div></div><h3 id="AutoMLPipeline-Modules-and-Instances"><a class="docs-heading-anchor" href="#AutoMLPipeline-Modules-and-Instances">AutoMLPipeline Modules and Instances</a><a id="AutoMLPipeline-Modules-and-Instances-1"></a><a class="docs-heading-anchor-permalink" href="#AutoMLPipeline-Modules-and-Instances" title="Permalink"></a></h3><p>Before continuing further with the tutorial, let us load the  necessary modules of AutoMLPipeline:</p><pre><code class="language-julia">using AutoMLPipeline, AutoMLPipeline.FeatureSelectors
using AutoMLPipeline.EnsembleMethods, AutoMLPipeline.CrossValidators
using AutoMLPipeline.DecisionTreeLearners, AutoMLPipeline.Pipelines
using AutoMLPipeline.BaseFilters, AutoMLPipeline.SKPreprocessors
using AutoMLPipeline.Utils, AutoMLPipeline.SKLearners</code></pre><p>Let us also create some instances of filters, transformers, and models that we can use to preprocess and model the dataset.</p><pre><code class="language-julia">#### Decomposition
pca = SKPreprocessor(&quot;PCA&quot;); fa = SKPreprocessor(&quot;FactorAnalysis&quot;);
ica = SKPreprocessor(&quot;FastICA&quot;)

#### Scaler
rb = SKPreprocessor(&quot;RobustScaler&quot;); pt = SKPreprocessor(&quot;PowerTransformer&quot;)
norm = SKPreprocessor(&quot;Normalizer&quot;); mx = SKPreprocessor(&quot;MinMaxScaler&quot;)

#### categorical preprocessing
ohe = OneHotEncoder()

#### Column selector
disc = CatNumDiscriminator()
catf = CatFeatureSelector(); numf = NumFeatureSelector()

#### Learners
rf = SKLearner(&quot;RandomForestClassifier&quot;); gb = SKLearner(&quot;GradientBoostingClassifier&quot;)
lsvc = SKLearner(&quot;LinearSVC&quot;); svc = SKLearner(&quot;SVC&quot;)
mlp = SKLearner(&quot;MLPClassifier&quot;); ada = SKLearner(&quot;AdaBoostClassifier&quot;)
jrf = RandomForest(); vote = VoteEnsemble(); stack = StackEnsemble()
best = BestLearner()</code></pre><h3 id="Processing-Categorical-Features"><a class="docs-heading-anchor" href="#Processing-Categorical-Features">Processing Categorical Features</a><a id="Processing-Categorical-Features-1"></a><a class="docs-heading-anchor-permalink" href="#Processing-Categorical-Features" title="Permalink"></a></h3><p>For the first illustration, let us extract categorical features of  the data and output some of them using the pipeline expression  and its interface:</p><pre><code class="language-">pop_cat = @pipeline catf 
tr_cat = fit_transform!(pop_cat,X,Y)
nothing #hide</code></pre><pre><code class="language-julia-repl">julia&gt; show5(tr_cat)
ERROR: UndefVarError: tr_cat not defined</code></pre><p>One may notice that instead of using <code>fit!</code> and <code>transform</code>,  the example uses <code>fit_transform!</code> instead. The latter is equivalent to calling <code>fit!</code> and <code>transform</code> in sequence which is handy for examining the final output of the transformation prior to  feeding it to the model.</p><p>Let us now transform the categorical features into one-hot-bit-encoding (ohe) and examine the results:</p><pre><code class="language-">pop_ohe = @pipeline catf |&gt; ohe
tr_ohe = fit_transform!(pop_ohe,X,Y)
nothing #hide</code></pre><pre><code class="language-julia-repl">julia&gt; show5(tr_ohe)
ERROR: UndefVarError: tr_ohe not defined</code></pre><h3 id="Processing-Numerical-Features"><a class="docs-heading-anchor" href="#Processing-Numerical-Features">Processing Numerical Features</a><a id="Processing-Numerical-Features-1"></a><a class="docs-heading-anchor-permalink" href="#Processing-Numerical-Features" title="Permalink"></a></h3><p>Let us have an example of extracting the numerical features of the data using different combinations of filters/transformers:</p><pre><code class="language-">pop_rb = @pipeline (numf |&gt; rb)
tr_rb = fit_transform!(pop_rb,X,Y)
nothing #hide</code></pre><pre><code class="language-julia-repl">julia&gt; show5(tr_rb)
ERROR: UndefVarError: tr_rb not defined</code></pre><h3 id="Concatenating-Extracted-Categorical-and-Numerical-Features"><a class="docs-heading-anchor" href="#Concatenating-Extracted-Categorical-and-Numerical-Features">Concatenating Extracted Categorical and Numerical Features</a><a id="Concatenating-Extracted-Categorical-and-Numerical-Features-1"></a><a class="docs-heading-anchor-permalink" href="#Concatenating-Extracted-Categorical-and-Numerical-Features" title="Permalink"></a></h3><p>For typical modeling workflow, input features are combinations of categorical features transformer to one-bit encoding together with numerical features normalized or scaled or transformed by decomposition. </p><p>Here is an example of a typical input feature:</p><pre><code class="language-">pop_com = @pipeline (numf |&gt; norm) + (catf |&gt; ohe)
tr_com = fit_transform!(pop_com,X,Y)
nothing #hide</code></pre><pre><code class="language-julia-repl">julia&gt; show5(tr_com)
ERROR: UndefVarError: tr_com not defined</code></pre><p>The column size from 6 grew to 60 after the hot-bit encoding was applied because of the large number of unique instances for the categorical columns. </p><h3 id="Performance-Evaluation-of-the-Pipeline"><a class="docs-heading-anchor" href="#Performance-Evaluation-of-the-Pipeline">Performance Evaluation of the Pipeline</a><a id="Performance-Evaluation-of-the-Pipeline-1"></a><a class="docs-heading-anchor-permalink" href="#Performance-Evaluation-of-the-Pipeline" title="Permalink"></a></h3><p>We can add a model at the end of the pipeline and evaluate the performance of the entire pipeline by cross-validation.</p><p>Let us use a linear SVC model and evaluate using 5-fold cross-validation.</p><pre><code class="language-julia-repl">julia&gt; Random.seed!(12345);

julia&gt; pop_lsvc = @pipeline ( (numf |&gt; rb) + (catf |&gt; ohe) + (numf |&gt; pt)) |&gt; lsvc;

julia&gt; tr_lsvc = crossvalidate(pop_lsvc,X,Y,&quot;balanced_accuracy_score&quot;,5)
ERROR: UndefVarError: X not defined</code></pre><p>What about using Gradient Boosting model?</p><pre><code class="language-julia-repl">julia&gt; Random.seed!(12345);

julia&gt; pop_gb = @pipeline ( (numf |&gt; rb) + (catf |&gt; ohe) + (numf |&gt; pt)) |&gt; gb;

julia&gt; tr_gb = crossvalidate(pop_gb,X,Y,&quot;balanced_accuracy_score&quot;,5)
ERROR: UndefVarError: X not defined</code></pre><p>What about using Random Forest model?</p><pre><code class="language-julia-repl">julia&gt; Random.seed!(12345);

julia&gt; pop_rf = @pipeline ( (numf |&gt; rb) + (catf |&gt; ohe) + (numf |&gt; pt)) |&gt; jrf;

julia&gt; tr_rf = crossvalidate(pop_rf,X,Y,&quot;balanced_accuracy_score&quot;,5)
ERROR: UndefVarError: X not defined</code></pre><p>Let&#39;s evaluate several learners which is a typical workflow in searching for the optimal model.</p><pre><code class="language-">using Random
using DataFrames: DataFrame, nrow,ncol

using AutoMLPipeline

Random.seed!(1)
jrf = RandomForest()
ada = SKLearner(&quot;AdaBoostClassifier&quot;)
sgd = SKLearner(&quot;SGDClassifier&quot;)
tree = PrunedTree()
std = SKPreprocessor(&quot;StandardScaler&quot;)
disc = CatNumDiscriminator()
lsvc = SKLearner(&quot;LinearSVC&quot;)

learners = DataFrame()
for learner in [jrf,ada,sgd,tree,lsvc]
  pcmc = @pipeline disc |&gt; ((catf |&gt; ohe) + (numf |&gt; std)) |&gt; learner
  println(learner.name)
  mean,sd,_ = crossvalidate(pcmc,X,Y,&quot;accuracy_score&quot;,10)
  global learners = vcat(learners,DataFrame(name=learner.name,mean=mean,sd=sd))
end;
nothing #hide</code></pre><pre><code class="language-julia-repl">julia&gt; @show learners;
learners = 0×0 DataFrame</code></pre><div class="admonition is-info"><header class="admonition-header">Note</header><div class="admonition-body"><p>It can be inferred from the results that linear SVC has the best performance with respect to the different pipelines evaluated. The compact expression supported by the  pipeline makes testing of the different combination of features  and models trivial. It makes performance evaluation   of the pipeline easily manageable in a systematic way.</p></div></div><h3 id="Learners-as-Filters"><a class="docs-heading-anchor" href="#Learners-as-Filters">Learners as Filters</a><a id="Learners-as-Filters-1"></a><a class="docs-heading-anchor-permalink" href="#Learners-as-Filters" title="Permalink"></a></h3><p>It is also possible to use learners in the middle of  expression to serve as filters and their outputs become  input to the final learner as illustrated below.</p><pre><code class="language-julia-repl">julia&gt; Random.seed!(1);

julia&gt; expr = @pipeline (
                          ((numf |&gt; pca) |&gt; gb) + ((numf |&gt; pca) |&gt; jrf)
                        ) |&gt; ohe |&gt; ada;

julia&gt; crossvalidate(expr,X,Y,&quot;accuracy_score&quot;,5)
ERROR: UndefVarError: X not defined</code></pre><p>It is important to take note that <code>ohe</code> is necessary because the outputs of the two learners (<code>gb</code> and <code>jrf</code>)  are categorical values that need to be hot-bit encoded before  feeding them to the final <code>ada</code> learner.</p><h3 id="Advanced-Expressions-using-Selector-Pipeline"><a class="docs-heading-anchor" href="#Advanced-Expressions-using-Selector-Pipeline">Advanced Expressions using Selector Pipeline</a><a id="Advanced-Expressions-using-Selector-Pipeline-1"></a><a class="docs-heading-anchor-permalink" href="#Advanced-Expressions-using-Selector-Pipeline" title="Permalink"></a></h3><p>You can use <code>*</code> operation as a selector  function which outputs the result of the best learner. Instead of looping over the different learners to identify the best learner, you can use the selector function  to automatically determine the best learner and output its  prediction. </p><pre><code class="language-julia-repl">julia&gt; Random.seed!(1);

julia&gt; pcmc = @pipeline disc |&gt; ((catf |&gt; ohe) + (numf |&gt; std)) |&gt;
                        (jrf * ada * sgd * tree * lsvc);

julia&gt; crossvalidate(pcmc,X,Y,&quot;accuracy_score&quot;,10)
ERROR: UndefVarError: X not defined</code></pre><p>Here is another example using the Selector Pipeline as a preprocessor in the feature extraction stage of the pipeline:</p><pre><code class="language-julia-repl">julia&gt; Random.seed!(1);

julia&gt; pjrf = @pipeline disc |&gt; ((catf |&gt; ohe) + (numf |&gt; std)) |&gt;
                        ((jrf * ada ) + (sgd * tree * lsvc)) |&gt; ohe |&gt; ada;

julia&gt; crossvalidate(pjrf,X,Y,&quot;accuracy_score&quot;)
ERROR: UndefVarError: X not defined</code></pre></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../../">« HOME</a><a class="docs-footer-nextpage" href="../preprocessing/">Preprocessing »</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> on <span class="colophon-date" title="Tuesday 1 September 2020 11:32">Tuesday 1 September 2020</span>. Using Julia version 1.5.1.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
